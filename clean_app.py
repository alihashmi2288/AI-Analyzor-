"""
AI Resume Analyzer Pro - Clean Version
Streamlined code without templates
Created by Syed Ali Hashmi
"""

import streamlit as st
import sqlite3
import hashlib
import re
from datetime import datetime

# Lazy imports for better performance
@st.cache_resource
def load_ml_libraries():
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.metrics.pairwise import cosine_similarity
    return TfidfVectorizer, cosine_similarity

@st.cache_resource
def load_file_libraries():
    try:
        import pdfplumber
    except ImportError:
        pdfplumber = None
    
    try:
        import docx2txt
    except ImportError:
        docx2txt = None
    
    return pdfplumber, docx2txt

@st.cache_resource
def load_ai_libraries():
    import google.generativeai as genai
    import plotly.graph_objects as go
    return genai, go

def create_pdf(content, title="Document"):
    """Create a real PDF document using FPDF2"""
    try:
        from fpdf import FPDF
        
        pdf = FPDF()
        pdf.add_page()
        pdf.set_font('helvetica', 'B', 16)
        pdf.cell(0, 10, title, new_x="LMARGIN", new_y="NEXT", align='C')
        pdf.ln(10)
        
        pdf.set_font('helvetica', '', 12)
        for line in content.split('\n'):
            if line.strip():
                words = line.split(' ')
                current_line = ''
                for word in words:
                    if len(current_line + word) < 80:
                        current_line += word + ' '
                    else:
                        if current_line:
                            pdf.cell(0, 6, current_line.strip(), new_x="LMARGIN", new_y="NEXT")
                        current_line = word + ' '
                if current_line:
                    pdf.cell(0, 6, current_line.strip(), new_x="LMARGIN", new_y="NEXT")
            else:
                pdf.ln(3)
        
        # Convert bytearray to bytes
        pdf_output = pdf.output()
        if isinstance(pdf_output, bytearray):
            return bytes(pdf_output)
        return pdf_output
    except:
        # Create a simple text-based fallback
        pdf_content = f"{title}\n{'='*len(title)}\n\n{content}"
        return pdf_content.encode('utf-8')

def create_docx(content, title="Document"):
    """Create a real DOCX document using python-docx"""
    try:
        from docx import Document
        from io import BytesIO
        
        doc = Document()
        doc.add_heading(title, 0)
        
        for line in content.split('\n'):
            if line.strip():
                doc.add_paragraph(line)
            else:
                doc.add_paragraph('')
        
        buffer = BytesIO()
        doc.save(buffer)
        buffer.seek(0)
        return buffer.getvalue()
    except:
        # Create RTF format as fallback
        rtf_content = f"{{\\rtf1\\ansi\\deff0 {{\\fonttbl{{\\f0 Times New Roman;}}}}\\f0\\fs24 \\b {title}\\b0\\par\\par{content.replace(chr(10), '\\par ')}\\par}}"
        return rtf_content.encode('utf-8')

# Page config
st.set_page_config(
    page_title="AI Resume Analyzer Pro",
    page_icon="üöÄ",
    layout="wide"
)

# Clean CSS
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1.5rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin-bottom: 1rem;
    }
    .metric-card {
        background: #f8f9fa;
        padding: 1rem;
        border-radius: 8px;
        border: 1px solid #dee2e6;
        text-align: center;
        margin: 0.5rem 0;
    }
    .feature-card {
        background: #f8f9fa;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #667eea;
        margin: 0.5rem 0;
        color: #333;
    }
    .progress-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1rem;
        border-radius: 8px;
        color: white;
        margin: 0.5rem 0;
    }
</style>
""", unsafe_allow_html=True)

# Database
def init_database():
    conn = sqlite3.connect('resumeai.db')
    cursor = conn.cursor()
    
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS users (
            id INTEGER PRIMARY KEY,
            username TEXT UNIQUE,
            email TEXT UNIQUE,
            password TEXT,
            created_at DATETIME DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS sessions (
            id INTEGER PRIMARY KEY,
            user_id INTEGER,
            resume_text TEXT,
            jd_text TEXT,
            match_score REAL,
            ats_score REAL,
            created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (user_id) REFERENCES users (id)
        )
    ''')
    
    conn.commit()
    conn.close()

init_database()

def hash_password(password):
    return hashlib.sha256(password.encode()).hexdigest()

def create_user(username, email, password):
    conn = sqlite3.connect('resumeai.db')
    cursor = conn.cursor()
    
    try:
        hashed_pw = hash_password(password)
        cursor.execute('INSERT INTO users (username, email, password) VALUES (?, ?, ?)',
                      (username, email, hashed_pw))
        conn.commit()
        conn.close()
        return True
    except sqlite3.IntegrityError:
        conn.close()
        return False

def authenticate_user(username, password):
    conn = sqlite3.connect('resumeai.db')
    cursor = conn.cursor()
    
    hashed_pw = hash_password(password)
    cursor.execute('SELECT id, username, email FROM users WHERE username = ? AND password = ?',
                  (username, hashed_pw))
    user = cursor.fetchone()
    conn.close()
    
    return user

def save_session(user_id, resume_text, jd_text, match_score, ats_score):
    conn = sqlite3.connect('resumeai.db')
    cursor = conn.cursor()
    
    cursor.execute('''INSERT INTO sessions 
                     (user_id, resume_text, jd_text, match_score, ats_score)
                     VALUES (?, ?, ?, ?, ?)''',
                  (user_id, resume_text, jd_text, match_score, ats_score))
    conn.commit()
    conn.close()

def get_user_sessions(user_id):
    conn = sqlite3.connect('resumeai.db')
    cursor = conn.cursor()
    
    cursor.execute('SELECT * FROM sessions WHERE user_id = ? ORDER BY created_at DESC',
                  (user_id,))
    sessions = cursor.fetchall()
    conn.close()
    
    return sessions

# Core functions


def extract_text_from_pdf(uploaded_file):
    try:
        pdfplumber, _ = load_file_libraries()
        text = ""
        uploaded_file.seek(0)
        
        with pdfplumber.open(uploaded_file) as pdf:
            for page_num, page in enumerate(pdf.pages):
                try:
                    # Method 1: Standard extraction
                    page_text = page.extract_text()
                    
                    # Method 2: Enhanced extraction with different settings
                    if not page_text or len(page_text.strip()) < 20:
                        page_text = page.extract_text(
                            x_tolerance=1,
                            y_tolerance=1,
                            layout=True,
                            x_density=7.25,
                            y_density=13
                        )
                    
                    # Method 3: Character-level extraction
                    if not page_text or len(page_text.strip()) < 20:
                        chars = page.chars
                        if chars:
                            page_text = "".join([char['text'] for char in chars])
                    
                    # Method 4: Word-level extraction
                    if not page_text or len(page_text.strip()) < 20:
                        words = page.extract_words()
                        if words:
                            page_text = " ".join([word['text'] for word in words])
                    
                    if page_text and len(page_text.strip()) > 5:
                        text += page_text + "\n\n"
                        
                except Exception as e:
                    continue
        
        # Fallback to PyPDF2 if pdfplumber fails
        if not text.strip() or len(text.strip()) < 50:
            try:
                import PyPDF2
                uploaded_file.seek(0)
                pdf_reader = PyPDF2.PdfReader(uploaded_file)
                fallback_text = ""
                for page_num in range(len(pdf_reader.pages)):
                    try:
                        page = pdf_reader.pages[page_num]
                        page_text = page.extract_text()
                        if page_text:
                            fallback_text += page_text + "\n\n"
                    except:
                        continue
                if fallback_text.strip():
                    text = fallback_text
            except ImportError:
                pass
            except Exception:
                pass
        
        # Final fallback to pymupdf if available
        if not text.strip() or len(text.strip()) < 50:
            try:
                import fitz
                uploaded_file.seek(0)
                doc = fitz.open(stream=uploaded_file.read(), filetype="pdf")
                fitz_text = ""
                for page in doc:
                    fitz_text += page.get_text() + "\n\n"
                doc.close()
                if fitz_text.strip():
                    text = fitz_text
            except:
                pass
        
        return text.strip() if text and len(text.strip()) > 10 else "Could not extract sufficient text from PDF. Please ensure it's not a scanned image or try converting to DOCX."
        
    except Exception as e:
        return f"PDF extraction failed: {str(e)}. Please try converting to DOCX."

def extract_text_from_docx(uploaded_file):
    try:
        _, docx2txt = load_file_libraries()
        uploaded_file.seek(0)
        text = docx2txt.process(uploaded_file)
        
        # If docx2txt fails, try python-docx as fallback
        if not text or len(text.strip()) < 10:
            text = extract_docx_fallback(uploaded_file)
        
        return text.strip() if text else "No text could be extracted from this DOCX file."
        
    except Exception as e:
        return extract_docx_fallback(uploaded_file)

def extract_docx_fallback(uploaded_file):
    """Fallback DOCX extraction using python-docx"""
    try:
        from docx import Document
        uploaded_file.seek(0)
        
        doc = Document(uploaded_file)
        text = ""
        
        # Extract text from paragraphs
        for paragraph in doc.paragraphs:
            if paragraph.text.strip():
                text += paragraph.text + "\n"
        
        # Extract text from tables
        for table in doc.tables:
            for row in table.rows:
                for cell in row.cells:
                    if cell.text.strip():
                        text += cell.text + " "
                text += "\n"
        
        return text.strip() if text else "DOCX text extraction failed."
        
    except ImportError:
        return "Additional libraries required for DOCX processing. Please install python-docx."
    except Exception as e:
        return "DOCX file appears to be corrupted or in an unsupported format."

def clean_text(text):
    if not text:
        return ""
    # Preserve important punctuation and structure
    text = text.lower()
    # Replace multiple spaces with single space
    text = re.sub(r'\s+', ' ', text)
    # Remove special characters but keep important ones
    text = re.sub(r'[^\w\s.,;:!?()\-+#/]', ' ', text)
    # Clean up extra spaces around punctuation
    text = re.sub(r'\s+([.,;:!?()])', r'\1', text)
    text = re.sub(r'([.,;:!?()])\s+', r'\1 ', text)
    return text.strip()

def extract_key_phrases(text):
    """Extract important phrases and technical terms"""
    if not text:
        return set()
    
    key_phrases = set()
    
    # Extract capitalized terms (likely proper nouns, technologies)
    try:
        cap_terms = re.findall(r'\b[A-Z][a-zA-Z]{1,20}\b', text)
        key_phrases.update([p.lower() for p in cap_terms if len(p) > 1])
    except:
        pass
    
    # Extract technical patterns
    try:
        tech_patterns = re.findall(r'\b(?:API|SDK|UI|UX|AI|ML|REST|JSON|XML|HTML|CSS|SQL)\b', text, re.IGNORECASE)
        key_phrases.update([p.lower() for p in tech_patterns])
    except:
        pass
    
    # Extract version numbers and technical specs
    try:
        versions = re.findall(r'\b\w+\s*v?\d+(?:\.\d+)*\b', text, re.IGNORECASE)
        key_phrases.update([p.lower().strip() for p in versions if len(p.strip()) > 1])
    except:
        pass
    
    # Extract programming languages and frameworks
    try:
        prog_langs = re.findall(r'\b(?:python|java|javascript|react|angular|vue|node|express|django|flask)\b', text, re.IGNORECASE)
        key_phrases.update([p.lower() for p in prog_langs])
    except:
        pass
    
    return key_phrases

@st.cache_data
def calculate_match_score(resume_text, jd_text):
    if not resume_text or not jd_text:
        return 0
    
    TfidfVectorizer, cosine_similarity = load_ml_libraries()
    
    try:
        # Enhanced preprocessing
        clean_resume = clean_text(resume_text)
        clean_jd = clean_text(jd_text)
        
        # Extract key phrases for better matching
        resume_phrases = extract_key_phrases(resume_text)
        jd_phrases = extract_key_phrases(jd_text)
        
        # 1. Advanced TF-IDF with better parameters
        vectorizer = TfidfVectorizer(
            stop_words='english',
            max_features=5000,  # Increased for better coverage
            ngram_range=(1, 4),  # Include 4-grams for technical terms
            min_df=1,
            max_df=0.85,  # More restrictive to filter common words
            sublinear_tf=True,
            token_pattern=r'\b[a-zA-Z][a-zA-Z0-9+#.-]*\b'  # Better for technical terms
        )
        
        # Combine original text with key phrases for analysis
        enhanced_resume = clean_resume + ' ' + ' '.join(resume_phrases)
        enhanced_jd = clean_jd + ' ' + ' '.join(jd_phrases)
        
        tfidf_matrix = vectorizer.fit_transform([enhanced_resume, enhanced_jd])
        base_similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]
        
        # 2. Enhanced keyword analysis with context
        jd_words = set(clean_jd.split())
        resume_words = set(clean_resume.split())
        
        # Categorized keywords with weights
        critical_keywords = ['required', 'must', 'essential', 'mandatory', 'minimum']
        skill_keywords = ['experience', 'skills', 'proficient', 'expert', 'knowledge', 'familiar']
        action_keywords = ['manage', 'lead', 'develop', 'create', 'implement', 'design', 'build']
        
        # Calculate contextual matches
        exact_matches = len(jd_words & resume_words)
        critical_context = sum(2 for word in critical_keywords if word in jd_words and any(skill in resume_words for skill in jd_words))
        skill_matches = sum(1 for word in skill_keywords if word in jd_words and word in resume_words)
        action_matches = sum(1 for word in action_keywords if word in jd_words and word in resume_words)
        
        # 3. Key phrase matching (high value)
        phrase_overlap = len(resume_phrases & jd_phrases)
        phrase_score_raw = (phrase_overlap / max(1, len(jd_phrases))) if jd_phrases else 0
        
        # 4. Technical term matching with exact boundaries
        tech_terms_jd = set(re.findall(r'\b(?:python|java|javascript|react|angular|vue|sql|aws|azure|docker|kubernetes|git|api|rest|json|xml|html|css|node|express|django|flask|spring|hibernate)\b', clean_jd, re.IGNORECASE))
        tech_terms_resume = set(re.findall(r'\b(?:python|java|javascript|react|angular|vue|sql|aws|azure|docker|kubernetes|git|api|rest|json|xml|html|css|node|express|django|flask|spring|hibernate)\b', clean_resume, re.IGNORECASE))
        tech_overlap = len(tech_terms_jd & tech_terms_resume)
        tech_score_raw = (tech_overlap / max(1, len(tech_terms_jd))) if tech_terms_jd else 0
        
        # 5. Experience level matching
        jd_years = re.findall(r'(\d+)\+?\s*(?:years?|yrs?)', clean_jd)
        resume_years = re.findall(r'(\d+)\+?\s*(?:years?|yrs?)', clean_resume)
        
        exp_score = 0
        if jd_years and resume_years:
            jd_max_years = max([int(y) for y in jd_years])
            resume_max_years = max([int(y) for y in resume_years])
            exp_score = min(resume_max_years / jd_max_years, 1.2) * 0.8  # Cap at 120% with 80% weight
        
        # 6. Calculate final weighted score
        total_jd_words = len(jd_words)
        if total_jd_words == 0:
            return 0
        
        # Advanced weighted scoring
        tfidf_component = base_similarity * 35  # 35%
        keyword_component = (exact_matches / total_jd_words) * 25  # 25%
        phrase_component = phrase_score_raw * 20  # 20%
        tech_component = tech_score_raw * 15  # 15%
        context_component = (critical_context + skill_matches + action_matches) / max(1, total_jd_words) * 10  # 10%
        experience_component = exp_score * 5  # 5%
        
        final_score = (tfidf_component + keyword_component + phrase_component + 
                      tech_component + context_component + experience_component)
        
        # Apply quality multipliers
        if phrase_overlap >= 3:  # Strong phrase matching bonus
            final_score *= 1.1
        if tech_overlap >= 3:  # Strong technical alignment bonus
            final_score *= 1.05
        
        return min(round(final_score, 1), 100)
        
    except Exception as e:
        return 0

def calculate_ats_score(resume_text, jd_text):
    if not resume_text or not jd_text:
        return 0
    
    try:
        resume_lower = resume_text.lower()
        jd_lower = jd_text.lower()
        
        # Enhanced preprocessing
        clean_resume = clean_text(resume_text)
        clean_jd = clean_text(jd_text)
        
        jd_words = set(clean_jd.split())
        resume_words = set(clean_resume.split())
        
        if len(jd_words) == 0:
            return 0
        
        # 1. Precision keyword matching (30% weight)
        # Use exact word boundaries to prevent false matches
        exact_keyword_matches = 0
        for jd_word in jd_words:
            if len(jd_word) > 2:  # Skip very short words
                if re.search(rf'\b{re.escape(jd_word)}\b', clean_resume):
                    exact_keyword_matches += 1
        
        keyword_score = (exact_keyword_matches / len(jd_words)) * 30
        
        # 2. Enhanced action verbs with context (20% weight)
        action_patterns = {
            'leadership': [r'\b(?:managed|led|supervised|directed|coordinated|mentored|guided)\b'],
            'development': [r'\b(?:developed|created|built|designed|implemented|engineered|programmed)\b'],
            'improvement': [r'\b(?:improved|optimized|enhanced|streamlined|increased|reduced|accelerated)\b'],
            'achievement': [r'\b(?:achieved|delivered|completed|executed|accomplished|succeeded|exceeded)\b'],
            'collaboration': [r'\b(?:collaborated|partnered|worked with|coordinated with|liaised)\b']
        }
        
        action_score = 0
        for category, patterns in action_patterns.items():
            for pattern in patterns:
                matches = len(re.findall(pattern, resume_lower))
                action_score += min(matches * 2, 4)  # Max 4 per category
        
        action_score = min(action_score, 20)
        
        # 3. Advanced quantifiable achievements (18% weight)
        # More sophisticated number pattern recognition
        metrics_patterns = [
            r'\b\d+(?:[.,]\d+)*%\b',  # Percentages
            r'\$\d+(?:[.,]\d+)*[kKmMbB]?\b',  # Currency
            r'\b\d+(?:[.,]\d+)*[kKmMbB]?\+?\s*(?:users?|customers?|clients?)\b',  # User metrics
            r'\b\d+(?:[.,]\d+)*[kKmMbB]?\+?\s*(?:hours?|days?|weeks?|months?)\b',  # Time savings
            r'\b(?:increased|improved|reduced|decreased)\s+(?:by\s+)?\d+(?:[.,]\d+)*[%kKmMbB]?\b',  # Improvement metrics
            r'\b\d+(?:[.,]\d+)*[xX]\s*(?:faster|improvement|increase)\b'  # Multiplier metrics
        ]
        
        quantifiable_count = 0
        for pattern in metrics_patterns:
            matches = re.findall(pattern, resume_text, re.IGNORECASE)
            quantifiable_count += len(matches)
        
        quantifiable_score = min(quantifiable_count * 2, 18)
        
        # 4. Technical skills with exact matching (17% weight)
        tech_skills_expanded = {
            'programming': ['python', 'java', 'javascript', 'typescript', 'c\\+\\+', 'c#', 'php', 'ruby', 'go', 'rust', 'scala', 'kotlin'],
            'web_frontend': ['html5?', 'css3?', 'react', 'angular', 'vue\\.js', 'svelte', 'bootstrap', 'tailwind'],
            'web_backend': ['node\\.js', 'express', 'django', 'flask', 'spring', 'laravel', 'rails'],
            'databases': ['sql', 'mysql', 'postgresql', 'mongodb', 'redis', 'elasticsearch', 'cassandra', 'dynamodb'],
            'cloud_aws': ['aws', 'ec2', 's3', 'lambda', 'rds', 'cloudformation', 'ecs', 'eks'],
            'cloud_other': ['azure', 'gcp', 'google cloud', 'digital ocean', 'heroku'],
            'devops': ['docker', 'kubernetes', 'jenkins', 'gitlab ci', 'github actions', 'terraform', 'ansible'],
            'tools': ['git', 'jira', 'confluence', 'slack', 'figma', 'postman', 'swagger']
        }
        
        tech_score = 0
        for category, skills in tech_skills_expanded.items():
            jd_category_skills = [skill for skill in skills if re.search(rf'\b{skill}\b', jd_lower, re.IGNORECASE)]
            if jd_category_skills:
                resume_category_matches = sum(1 for skill in jd_category_skills 
                                            if re.search(rf'\b{skill}\b', resume_lower, re.IGNORECASE))
                category_score = (resume_category_matches / len(jd_category_skills)) * 3
                tech_score += min(category_score, 3)
        
        tech_score = min(tech_score, 17)
        
        # 5. Professional structure and ATS compatibility (10% weight)
        structure_checks = {
            'optimal_length': 1 if 800 <= len(resume_text) <= 2500 else 0.5 if 500 <= len(resume_text) <= 3500 else 0,
            'clear_sections': len([s for s in ['experience', 'education', 'skills', 'summary', 'objective'] if s in resume_lower]) / 5,
            'contact_info': 1 if re.search(r'\b[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}\b', resume_text) else 0,
            'phone_number': 1 if re.search(r'\b\d{3}[-.]?\d{3}[-.]?\d{4}\b', resume_text) else 0,
            'bullet_points': 1 if len(re.findall(r'^\s*[‚Ä¢\-\*]', resume_text, re.MULTILINE)) >= 5 else 0,
            'date_consistency': 1 if len(re.findall(r'\b(?:19|20)\d{2}\b', resume_text)) >= 2 else 0,
            'no_graphics': 1 if not re.search(r'\b(?:image|graphic|chart|table)\b', resume_lower) else 0.5
        }
        
        structure_score = sum(structure_checks.values()) * (10 / len(structure_checks))
        
        # 6. Industry and role-specific keywords (5% weight)
        # Dynamic industry detection based on JD
        industry_patterns = {
            'software': ['software', 'development', 'programming', 'coding', 'algorithm'],
            'data': ['data', 'analytics', 'machine learning', 'statistics', 'visualization'],
            'management': ['management', 'leadership', 'strategy', 'planning', 'team'],
            'marketing': ['marketing', 'campaign', 'brand', 'digital', 'social media'],
            'sales': ['sales', 'revenue', 'client', 'customer', 'business development']
        }
        
        detected_industry = None
        max_industry_score = 0
        
        for industry, keywords in industry_patterns.items():
            industry_presence = sum(1 for kw in keywords if kw in jd_lower)
            if industry_presence > max_industry_score:
                max_industry_score = industry_presence
                detected_industry = industry
        
        industry_score = 0
        if detected_industry and detected_industry in industry_patterns:
            industry_keywords = industry_patterns[detected_industry]
            jd_industry_terms = sum(1 for kw in industry_keywords if kw in jd_lower)
            resume_industry_terms = sum(1 for kw in industry_keywords if kw in resume_lower)
            if jd_industry_terms > 0:
                industry_score = (resume_industry_terms / jd_industry_terms) * 5
        
        # Calculate final ATS score with precision weighting
        total_score = (keyword_score + action_score + quantifiable_score + 
                      tech_score + structure_score + industry_score)
        
        # Apply bonus for strong technical alignment
        if tech_score >= 12:  # Strong technical match
            total_score *= 1.05
        
        # Apply penalty for poor structure
        if structure_score < 5:
            total_score *= 0.95
        
        return min(round(total_score, 1), 100)
        
    except Exception as e:
        return 0

# Gemini AI
def get_gemini_api_key():
    try:
        return st.secrets["GEMINI_API_KEY"]
    except:
        return "AIzaSyCd-ay8KNBEkjWluWFwOzWddvZftS5CXtc"

def generate_with_gemini(prompt, max_tokens=1000):
    genai, _ = load_ai_libraries()
    api_key = get_gemini_api_key()
    
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-2.0-flash')
        response = model.generate_content(prompt)
        return response.text.strip()
    except Exception as e:
        return f"Error: {str(e)}"

@st.cache_data
def create_score_gauge(score, title):
    _, go = load_ai_libraries()
    fig = go.Figure(go.Indicator(
        mode="gauge+number",
        value=score,
        domain={'x': [0, 1], 'y': [0, 1]},
        title={'text': title},
        gauge={
            'axis': {'range': [None, 100]},
            'bar': {'color': "#667eea"},
            'steps': [
                {'range': [0, 50], 'color': "lightgray"},
                {'range': [50, 80], 'color': "yellow"},
                {'range': [80, 100], 'color': "green"}
            ]
        }
    ))
    fig.update_layout(height=300)
    return fig

def generate_detailed_recommendations(match_score, ats_score, resume_text, jd_text):
    """Generate detailed, actionable recommendations"""
    recommendations = []
    
    # Analyze missing keywords
    jd_words = set(clean_text(jd_text).split())
    resume_words = set(clean_text(resume_text).split())
    missing_keywords = list(jd_words - resume_words)[:5]
    
    # Check for action verbs
    action_verbs = ['managed', 'led', 'developed', 'created', 'improved', 'achieved', 'implemented', 'designed']
    action_count = sum(1 for verb in action_verbs if verb in resume_text.lower())
    
    # Check for numbers/metrics
    numbers = re.findall(r'\d+[%$]?', resume_text)
    
    # Generate specific recommendations
    if match_score < 70:
        if missing_keywords:
            recommendations.append(f"üéØ **Add Key Terms**: Include these important keywords: {', '.join(missing_keywords[:3])}")
        recommendations.append("üîç **Skills Alignment**: Review job requirements and highlight matching experience more prominently")
        recommendations.append("üìù **Content Optimization**: Rewrite job descriptions to better match the target role's language")
    
    if ats_score < 70:
        if action_count < 5:
            recommendations.append("‚ö° **Action Verbs**: Use more powerful action verbs like 'spearheaded', 'orchestrated', 'pioneered'")
        if len(numbers) < 3:
            recommendations.append("üìà **Quantify Results**: Add specific numbers, percentages, or dollar amounts to show impact")
        recommendations.append("üé® **Format Improvement**: Ensure clean formatting with consistent fonts, spacing, and bullet points")
    
    if match_score >= 70 and ats_score >= 70:
        recommendations.append("üéâ **Excellent Foundation**: Your resume shows strong alignment with the job requirements")
        recommendations.append("üï∞Ô∏è **Fine-Tuning**: Consider customizing your professional summary for this specific role")
        recommendations.append("üîó **LinkedIn Sync**: Ensure your LinkedIn profile matches your resume's key points")
        recommendations.append("üí¨ **Cover Letter**: Write a compelling cover letter that tells your unique story")
    
    # Always include industry-specific advice
    if 'software' in jd_text.lower() or 'developer' in jd_text.lower():
        recommendations.append("üíª **Tech Focus**: Highlight programming languages, frameworks, and technical projects")
    elif 'marketing' in jd_text.lower():
        recommendations.append("üìä **Marketing Metrics**: Include campaign results, conversion rates, and ROI improvements")
    elif 'sales' in jd_text.lower():
        recommendations.append("üí∞ **Sales Numbers**: Emphasize quota achievements, revenue generated, and client acquisition")
    else:
        recommendations.append("üéØ **Industry Alignment**: Research industry-specific terminology and incorporate relevant buzzwords")
    
    # Ensure minimum 4 recommendations
    while len(recommendations) < 4:
        additional_tips = [
            "üìù **Professional Summary**: Craft a compelling 2-3 line summary at the top",
            "üéì **Education Relevance**: Highlight relevant coursework, certifications, or training",
            "üîç **Keyword Density**: Naturally incorporate job-specific terms throughout your resume",
            "üìÖ **Recent Experience**: Emphasize your most recent and relevant work experience",
            "üéÜ **Achievement Focus**: Transform job duties into accomplishment statements"
        ]
        for tip in additional_tips:
            if tip not in recommendations:
                recommendations.append(tip)
                break
    
    return recommendations[:6]  # Return max 6 recommendations

def main():
    # Initialize session state
    if 'authenticated' not in st.session_state:
        st.session_state.authenticated = False
    if 'user_data' not in st.session_state:
        st.session_state.user_data = None
    
    # Simple Header
    st.markdown("""
    <div class="main-header">
        <h1>üöÄ AI Resume Analyzer Pro</h1>
        <p>Professional AI-Powered Resume Analysis & Optimization</p>
        <small>Created by Syed Ali Hashmi</small>
    </div>
    """, unsafe_allow_html=True)
    
    # Authentication
    if not st.session_state.authenticated:
        show_auth_page()
        return
    
    # Main app
    show_main_app()

def show_auth_page():
    col1, col2, col3 = st.columns([1, 2, 1])
    
    with col2:
        st.markdown("### Welcome to AI Resume Analyzer Pro")
        
        tab1, tab2 = st.tabs(["Sign In", "Sign Up"])
        
        with tab1:
            with st.form("login_form"):
                username = st.text_input("Username")
                password = st.text_input("Password", type="password")
                
                if st.form_submit_button("Sign In", use_container_width=True):
                    user = authenticate_user(username, password)
                    if user:
                        st.session_state.authenticated = True
                        st.session_state.user_data = {
                            'id': user[0],
                            'username': user[1],
                            'email': user[2]
                        }
                        st.rerun()
                    else:
                        st.error("Invalid credentials")
        
        with tab2:
            with st.form("signup_form"):
                new_username = st.text_input("Choose Username")
                new_email = st.text_input("Email")
                new_password = st.text_input("Password", type="password")
                confirm_password = st.text_input("Confirm Password", type="password")
                
                if st.form_submit_button("Sign Up", use_container_width=True):
                    if new_password != confirm_password:
                        st.error("Passwords don't match")
                    elif len(new_password) < 6:
                        st.error("Password must be at least 6 characters")
                    elif create_user(new_username, new_email, new_password):
                        st.success("Account created! Please sign in.")
                    else:
                        st.error("Username or email already exists")

def show_main_app():
    # Sidebar
    with st.sidebar:
        st.markdown(f"### Welcome, {st.session_state.user_data['username']}! üëã")
        
        if st.button("üö™ Logout"):
            st.session_state.authenticated = False
            st.session_state.user_data = None
            st.rerun()
        
        st.divider()
        
        # User progress tracking
        if st.session_state.user_data:
            sessions = get_user_sessions(st.session_state.user_data['id'])
            if sessions:
                avg_score = sum(s[4] for s in sessions) / len(sessions)
                best_score = max(s[4] for s in sessions)
                
                st.markdown("### üìà Your Progress")
                st.markdown(f'<div class="progress-card">üéØ Analyses: {len(sessions)}<br>üìà Avg Score: {avg_score:.1f}%<br>üèÜ Best: {best_score:.1f}%</div>', unsafe_allow_html=True)
        
        st.markdown("### üéØ Features")
        
        features = [
            "üéØ AI Resume Analysis",
            "üìä ATS Optimization", 
            "üíå Cover Letter Generation",
            "‚ùì Interview Preparation",
            "ü§ñ AI Career Tools",
            "üìà Advanced Analytics"
        ]
        
        for feature in features:
            st.markdown(f'<div class="feature-card">{feature}</div>', unsafe_allow_html=True)
        
        st.markdown("---")
        st.markdown("**Created by Syed Ali Hashmi**")
        st.markdown("üíº [LinkedIn](https://linkedin.com/in/hashmiali2288)")
        st.markdown("üíª [GitHub](https://github.com/alihashmi2288)")
    
    # Main tabs
    tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs([
        "üéØ Analysis",
        "üìù AI Rewrite", 
        "üíå Cover Letters",
        "‚ùì Interview Prep",
        "ü§ñ AI Tools",
        "üìà Analytics",
        "üìö History"
    ])
    
    with tab1:
        show_analysis()
    
    with tab2:
        show_rewrite()
    
    with tab3:
        show_cover_letters()
    
    with tab4:
        show_interview_prep()
    
    with tab5:
        show_ai_tools()
    
    with tab6:
        show_analytics_dashboard()
    
    with tab7:
        show_history()

def show_analysis():
    st.header("üéØ Resume Analysis")
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("üìÑ Upload Resume")
        resume_file = st.file_uploader("Choose resume file", type=['pdf', 'docx'])
        
        if resume_file:
            with st.spinner("üìÑ Processing file..."):
                try:
                    if resume_file.type == "application/pdf" or resume_file.name.lower().endswith('.pdf'):
                        resume_text = extract_text_from_pdf(resume_file)
                    elif resume_file.type == "application/vnd.openxmlformats-officedocument.wordprocessingml.document" or resume_file.name.lower().endswith('.docx'):
                        resume_text = extract_text_from_docx(resume_file)
                    else:
                        st.error("Unsupported file type. Please upload PDF or DOCX files only.")
                        return
                    
                    if resume_text and len(resume_text.strip()) > 20:
                        st.session_state.resume_text = resume_text
                        word_count = len(resume_text.split())
                        st.success(f"‚úÖ {resume_file.name} uploaded successfully ({word_count} words extracted)")
                        
                        # Show preview of extracted text
                        with st.expander("üìÑ Preview extracted text"):
                            st.text_area("Extracted content:", resume_text[:500] + "..." if len(resume_text) > 500 else resume_text, height=150, disabled=True)
                    else:
                        st.error(f"‚ùå Could not extract sufficient text from {resume_file.name}. Error: {resume_text}")
                        st.info("üí° Try: Ensuring the PDF contains selectable text (not scanned images), converting to DOCX format, or checking file integrity.")
                        
                except Exception as e:
                    st.error(f"‚ùå Error processing {resume_file.name}: {str(e)}")
                    st.info("üí° Please try a different file or format.")
    
    with col2:
        st.subheader("üìã Job Description")
        jd_input = st.text_area("Paste job description:", height=200)
        
        if jd_input:
            st.session_state.jd_text = jd_input
            st.info(f"üìä Job description added")
    
    # Analysis
    if st.button("üöÄ Analyze Resume", type="primary", use_container_width=True):
        if hasattr(st.session_state, 'resume_text') and hasattr(st.session_state, 'jd_text'):
            with st.spinner("üîÑ Analyzing..."):
                match_score = calculate_match_score(st.session_state.resume_text, st.session_state.jd_text)
                ats_score = calculate_ats_score(st.session_state.resume_text, st.session_state.jd_text)
                
                st.session_state.match_score = match_score
                st.session_state.ats_score = ats_score
                
                # Show improvement before saving new session
                if st.session_state.user_data:
                    prev_sessions = get_user_sessions(st.session_state.user_data['id'])
                    if prev_sessions:
                        prev_match = prev_sessions[0][4]
                        prev_ats = prev_sessions[0][5]
                        
                        match_improvement = match_score - prev_match
                        ats_improvement = ats_score - prev_ats
                        
                        if match_improvement > 0 or ats_improvement > 0:
                            st.success(f"üìà Improvement: Match {match_improvement:+.1f}%, ATS {ats_improvement:+.1f}%")
                        elif match_improvement < 0 or ats_improvement < 0:
                            st.warning(f"üìâ Change: Match {match_improvement:+.1f}%, ATS {ats_improvement:+.1f}%")
                    
                    # Save new session
                    save_session(
                        st.session_state.user_data['id'],
                        st.session_state.resume_text,
                        st.session_state.jd_text,
                        match_score,
                        ats_score
                    )
            
            # Results
            st.subheader("üìä Results")
            
            col1, col2 = st.columns(2)
            with col1:
                fig1 = create_score_gauge(match_score, "Match Score")
                st.plotly_chart(fig1, use_container_width=True)
            
            with col2:
                fig2 = create_score_gauge(ats_score, "ATS Score")
                st.plotly_chart(fig2, use_container_width=True)
            
            # Enhanced Recommendations
            st.subheader("üí° Detailed Recommendations")
            
            recommendations = generate_detailed_recommendations(match_score, ats_score, st.session_state.resume_text, st.session_state.jd_text)
            
            for i, rec in enumerate(recommendations, 1):
                st.markdown(f'<div class="feature-card"><strong>{i}.</strong> {rec}</div>', unsafe_allow_html=True)
        else:
            st.error("Please upload resume and add job description")

def show_rewrite():
    st.header("üìù AI Resume Rewrite")
    
    if hasattr(st.session_state, 'resume_text') and hasattr(st.session_state, 'jd_text'):
        if st.button("‚ú® Rewrite My Resume", type="primary"):
            with st.spinner("ü§ñ AI is optimizing your resume..."):
                prompt = f"""
                Rewrite this resume to match the job description perfectly:
                
                Original Resume: {st.session_state.resume_text[:2000]}
                Target Job: {st.session_state.jd_text[:1000]}
                
                Instructions:
                1. Keep same structure but improve content
                2. Add keywords from job description
                3. Quantify achievements where possible
                4. Use strong action verbs
                5. Make it ATS-friendly
                
                Return the complete improved resume.
                """
                
                rewritten_resume = generate_with_gemini(prompt, max_tokens=1500)
                st.session_state.rewritten_resume = rewritten_resume
        
        # Multi-version resume generator
        if hasattr(st.session_state, 'resume_text') and hasattr(st.session_state, 'jd_text'):
            st.divider()
            st.subheader("üîÑ Multi-Version Generator")
            
            col1, col2 = st.columns(2)
            with col1:
                version_type = st.selectbox("Resume Version:", [
                    "Executive Summary Focus",
                    "Technical Skills Focus", 
                    "Achievement Focus",
                    "Entry-Level Friendly",
                    "Career Change Focus"
                ])
            
            with col2:
                if st.button("‚ú® Generate Version", key="multi_version"):
                    with st.spinner(f"ü§ñ Creating {version_type.lower()} version..."):
                        version_prompt = f"""
                        Create a {version_type.lower()} version of this resume:
                        
                        Original Resume: {st.session_state.resume_text[:1500]}
                        Job Description: {st.session_state.jd_text[:800]}
                        
                        Focus on {version_type.lower()} while maintaining ATS compatibility.
                        Keep it concise and impactful.
                        """
                        
                        version_resume = generate_with_gemini(version_prompt, max_tokens=1200)
                        st.session_state[f"version_{version_type}"] = version_resume
            
            # Show generated version
            if f"version_{version_type}" in st.session_state:
                st.text_area(
                    f"{version_type} Version:",
                    st.session_state[f"version_{version_type}"],
                    height=300,
                    key=f"edit_{version_type}"
                )
                
                st.download_button(
                    f"üì• Download {version_type}",
                    st.session_state[f"version_{version_type}"],
                    f"resume_{version_type.lower().replace(' ', '_')}.txt",
                    "text/plain"
                )
        
        if hasattr(st.session_state, 'rewritten_resume'):
            st.subheader("üìù Your Optimized Resume")
            
            edited_resume = st.text_area(
                "Edit your resume:", 
                value=st.session_state.rewritten_resume, 
                height=400
            )
            
            st.session_state.rewritten_resume = edited_resume
            
            # Download
            st.subheader("üì• Download")
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.download_button(
                    "üìÑ TXT",
                    edited_resume,
                    "optimized_resume.txt",
                    "text/plain",
                    use_container_width=True
                )
            
            with col2:
                html_content = f"""
                <!DOCTYPE html>
                <html>
                <head>
                    <meta charset="UTF-8">
                    <title>Optimized Resume</title>
                    <style>
                        body {{ font-family: Arial, sans-serif; line-height: 1.6; margin: 40px; max-width: 800px; }}
                        h1, h2 {{ color: #333; }}
                        .header {{ text-align: center; margin-bottom: 30px; }}
                        .section {{ margin: 20px 0; }}
                        @media print {{ body {{ margin: 20px; }} }}
                    </style>
                </head>
                <body>
                    <div class="header">
                        <h1>Professional Resume</h1>
                        <p>Generated by AI Resume Analyzer Pro</p>
                    </div>
                    <div class="section">
                        {edited_resume.replace(chr(10), '<br>')}
                    </div>
                </body>
                </html>
                """
                st.download_button(
                    "üåê HTML",
                    html_content,
                    "optimized_resume.html",
                    "text/html",
                    use_container_width=True
                )
            

            
            with col3:
                docx_data = create_docx(edited_resume, "Professional Resume")
                st.download_button(
                    "üìÑ DOCX",
                    docx_data,
                    "optimized_resume.docx",
                    "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                    use_container_width=True
                )
            

    else:
        st.info("üìÑ Please analyze a resume first")

def show_cover_letters():
    st.header("üíå AI Cover Letter Generator")
    
    if hasattr(st.session_state, 'resume_text') and hasattr(st.session_state, 'jd_text'):
        col1, col2 = st.columns([1, 1])
        
        with col1:
            job_title = st.text_input("Job Title", placeholder="e.g., Software Engineer")
            template_type = st.selectbox("Style", ["Formal", "Modern", "Creative", "Short"])
        
        if st.button("‚ú® Generate Cover Letter", type="primary"):
            with st.spinner(f"ü§ñ Creating {template_type.lower()} cover letter..."):
                prompt = f"""
                Write a {template_type.lower()} cover letter for: {job_title}
                
                Resume: {st.session_state.resume_text[:1500]}
                Job Description: {st.session_state.jd_text[:1000]}
                
                Requirements:
                - Use {template_type.lower()} style
                - 3-4 paragraphs maximum
                - Highlight relevant skills
                - Professional closing
                - Under 400 words
                """
                
                cover_letter = generate_with_gemini(prompt)
                
                st.subheader(f"üìÑ Your {template_type} Cover Letter")
                edited_letter = st.text_area("Edit cover letter:", cover_letter, height=400)
                
                # Download
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.download_button(
                        "üìÑ TXT",
                        edited_letter,
                        f"cover_letter_{template_type.lower()}.txt",
                        "text/plain",
                        use_container_width=True
                    )
                
                with col2:
                    html_letter = f"<html><body><div style='font-family: Arial; line-height: 1.6; max-width: 600px; margin: 0 auto; padding: 20px;'>{edited_letter.replace(chr(10), '<br>')}</div></body></html>"
                    st.download_button(
                        "üåê HTML",
                        html_letter,
                        f"cover_letter_{template_type.lower()}.html",
                        "text/html",
                        use_container_width=True
                    )
                

                
                with col3:
                    docx_data = create_docx(edited_letter, f"{template_type} Cover Letter")
                    st.download_button(
                        "üìÑ DOCX",
                        docx_data,
                        f"cover_letter_{template_type.lower()}.docx",
                        "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                        use_container_width=True
                    )

    else:
        st.info("üìÑ Please analyze a resume first")

def show_interview_prep():
    st.header("‚ùì AI Interview Preparation")
    
    if hasattr(st.session_state, 'resume_text') and hasattr(st.session_state, 'jd_text'):
        if st.button("üé§ Generate Interview Questions", type="primary"):
            with st.spinner("ü§ñ Preparing interview questions..."):
                prompt = f"""
                Generate 8 interview questions based on:
                
                Resume: {st.session_state.resume_text[:1500]}
                Job Description: {st.session_state.jd_text[:1000]}
                
                Create:
                - 4 technical/role-specific questions
                - 4 behavioral questions
                
                For each question provide:
                1. The question
                2. Key points to address
                3. Example answer framework
                
                Format as numbered list.
                """
                
                questions = generate_with_gemini(prompt, max_tokens=1200)
                
                st.subheader("üìã Interview Questions")
                st.markdown(questions)
                
                # Download
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.download_button(
                        "üìÑ TXT",
                        questions,
                        "interview_questions.txt",
                        "text/plain",
                        use_container_width=True
                    )
                
                with col2:
                    html_questions = f"<html><body><div style='font-family: Arial; line-height: 1.6; max-width: 800px; margin: 0 auto; padding: 20px;'><h1>Interview Preparation</h1>{questions.replace(chr(10), '<br>')}</div></body></html>"
                    st.download_button(
                        "üåê HTML",
                        html_questions,
                        "interview_questions.html",
                        "text/html",
                        use_container_width=True
                    )
                

                
                with col3:
                    docx_data = create_docx(questions, "Interview Preparation")
                    st.download_button(
                        "üìÑ DOCX",
                        docx_data,
                        "interview_questions.docx",
                        "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                        use_container_width=True
                    )

    else:
        st.info("üìÑ Please analyze a resume first")

def show_history():
    st.header("üìö Analysis History")
    
    if st.session_state.user_data:
        sessions = get_user_sessions(st.session_state.user_data['id'])
        
        if sessions:
            st.subheader(f"üìä Your Past {len(sessions)} Analyses")
            
            for session in sessions:
                with st.expander(f"Analysis from {session[7][:16]} - Score: {session[4]}%"):
                    col1, col2, col3 = st.columns([2, 2, 1])
                    
                    with col1:
                        st.metric("Match Score", f"{session[4]}%")
                        st.metric("ATS Score", f"{session[5]}%")
                    
                    with col2:
                        st.write("**Resume Preview:**")
                        st.write(session[2][:200] + "..." if len(session[2]) > 200 else session[2])
                    
                    with col3:
                        if st.button(f"Load", key=f"load_{session[0]}"):
                            st.session_state.resume_text = session[2]
                            st.session_state.jd_text = session[3]
                            st.session_state.match_score = session[4]
                            st.session_state.ats_score = session[5]
                            st.success("Session loaded!")
        else:
            st.info("üìù No analysis history yet")

def show_ai_tools():
    st.header("ü§ñ Enhanced AI Career Tools")
    
    # Display available tools in a nice layout
    st.markdown("### üéØ Available AI Tools")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        <div style="background: #f8f9fa; padding: 1rem; border-radius: 8px; border-left: 4px solid #667eea; margin: 0.5rem 0; color: #333;">
            <strong>üí∞ Salary Negotiation Guide</strong><br>
            <small style="color: #666;">Personalized negotiation strategy with market data</small>
        </div>
        
        <div style="background: #f8f9fa; padding: 1rem; border-radius: 8px; border-left: 4px solid #667eea; margin: 0.5rem 0; color: #333;">
            <strong>üíº LinkedIn Optimization</strong><br>
            <small style="color: #666;">Profile enhancement with SEO tips</small>
        </div>
        
        <div style="background: #f8f9fa; padding: 1rem; border-radius: 8px; border-left: 4px solid #667eea; margin: 0.5rem 0; color: #333;">
            <strong>üéØ Interview Answer Generator</strong><br>
            <small style="color: #666;">Personalized STAR method answers</small>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown("""
        <div style="background: #f8f9fa; padding: 1rem; border-radius: 8px; border-left: 4px solid #667eea; margin: 0.5rem 0; color: #333;">
            <strong>üè¢ Company Research Report</strong><br>
            <small style="color: #666;">Comprehensive company analysis for interviews</small>
        </div>
        
        <div style="background: #f8f9fa; padding: 1rem; border-radius: 8px; border-left: 4px solid #667eea; margin: 0.5rem 0; color: #333;">
            <strong>üìß Professional Email Generator</strong><br>
            <small style="color: #666;">Professional communication templates</small>
        </div>
        
        <div style="background: #f8f9fa; padding: 1rem; border-radius: 8px; border-left: 4px solid #667eea; margin: 0.5rem 0; color: #333;">
            <strong>üîÑ Career Transition Planner</strong><br>
            <small style="color: #666;">Strategic career change guidance</small>
        </div>
        """, unsafe_allow_html=True)
    
    st.divider()
    
    ai_feature = st.selectbox(
        "üöÄ Select a tool to get started:",
        [
            "üí∞ Salary Negotiation Guide",
            "üè¢ Company Research Report", 
            "üíº LinkedIn Optimization",
            "üìß Professional Email Generator",
            "üéØ Interview Answer Generator",
            "üîÑ Career Transition Planner"
        ]
    )
    
    if "üí∞ Salary Negotiation" in ai_feature:
        st.subheader("üí∞ Salary Negotiation Guide")
        col1, col2 = st.columns(2)
        with col1:
            job_title = st.text_input("Job Title:", placeholder="e.g., Software Engineer")
        with col2:
            location = st.text_input("Location:", placeholder="e.g., San Francisco, CA")
        
        if st.button("‚ú® Generate Negotiation Guide", type="primary"):
            if hasattr(st.session_state, 'resume_text') and hasattr(st.session_state, 'jd_text'):
                with st.spinner("ü§ñ Creating negotiation strategy..."):
                    prompt = f"""
                    Create a comprehensive salary negotiation guide for:
                    
                    Job Title: {job_title}
                    Location: {location}
                    Resume: {st.session_state.resume_text[:1500]}
                    Job Description: {st.session_state.jd_text[:1000]}
                    
                    Provide:
                    1. Estimated salary range for this role and location
                    2. Key value propositions to highlight
                    3. 5 specific negotiation talking points
                    4. Non-salary benefits to consider
                    5. Sample negotiation scripts
                    6. Red flags to avoid
                    """
                    
                    guide = generate_with_gemini(prompt, max_tokens=1500)
                    st.markdown(guide)
                    st.download_button(
                        "üì• Download Guide",
                        guide,
                        "salary_negotiation_guide.txt",
                        "text/plain"
                    )
            else:
                st.error("Please analyze a resume first")
    
    elif "üè¢ Company Research" in ai_feature:
        st.subheader("üè¢ Company Research Report")
        col1, col2 = st.columns(2)
        with col1:
            company_name = st.text_input("Company Name:", placeholder="e.g., Google")
        with col2:
            job_title = st.text_input("Job Title:", placeholder="e.g., Product Manager")
        
        if st.button("‚ú® Generate Research Report", type="primary"):
            if company_name and job_title:
                with st.spinner("ü§ñ Researching company..."):
                    prompt = f"""
                    Create a detailed company research report for interview preparation:
                    
                    Company: {company_name}
                    Position: {job_title}
                    
                    Provide:
                    1. Company Overview (mission, values, recent news)
                    2. Industry Position and Competitors
                    3. Recent Financial Performance
                    4. Company Culture and Work Environment
                    5. Leadership Team
                    6. Recent Product Launches
                    7. Interview Questions Likely to be Asked
                    8. Questions to Ask the Interviewer
                    9. How to Align Your Experience
                    """
                    
                    report = generate_with_gemini(prompt, max_tokens=2000)
                    st.markdown(report)
                    st.download_button(
                        "üì• Download Report",
                        report,
                        f"{company_name.lower()}_research_report.txt",
                        "text/plain"
                    )
            else:
                st.error("Please enter company name and job title")
    
    elif "üíº LinkedIn Optimization" in ai_feature:
        st.subheader("üíº LinkedIn Profile Optimization")
        target_role = st.text_input("Target Role:", placeholder="e.g., Senior Data Scientist")
        
        if st.button("‚ú® Optimize LinkedIn Profile", type="primary"):
            if hasattr(st.session_state, 'resume_text') and target_role:
                with st.spinner("ü§ñ Optimizing LinkedIn profile..."):
                    prompt = f"""
                    Optimize LinkedIn profile for the target role:
                    
                    Current Resume: {st.session_state.resume_text[:1500]}
                    Target Role: {target_role}
                    
                    Provide optimized versions of:
                    1. Professional Headline (under 120 characters)
                    2. About Section (compelling summary, 2-3 paragraphs)
                    3. Experience Descriptions (for top 3 roles)
                    4. Skills Section (top 15 skills to highlight)
                    5. Keywords to include throughout profile
                    6. Content Strategy (what to post/share)
                    7. LinkedIn SEO tips
                    """
                    
                    optimization = generate_with_gemini(prompt, max_tokens=1800)
                    st.markdown(optimization)
                    st.download_button(
                        "üì• Download Optimization",
                        optimization,
                        "linkedin_optimization.txt",
                        "text/plain"
                    )
            else:
                st.error("Please analyze a resume first and enter target role")
    
    elif "üìß Professional Email" in ai_feature:
        st.subheader("üìß Professional Email Generator")
        col1, col2 = st.columns(2)
        with col1:
            email_type = st.selectbox("Email Type:", [
                "Thank You After Interview",
                "Follow-up Email", 
                "Networking Outreach",
                "Job Application",
                "Rejection Response"
            ])
        with col2:
            recipient_name = st.text_input("Recipient Name:", placeholder="e.g., John Smith")
        
        company_name = st.text_input("Company Name:", placeholder="e.g., TechCorp")
        additional_context = st.text_area("Additional Context:", placeholder="Any specific details to include...")
        
        if st.button("‚ú® Generate Email", type="primary"):
            with st.spinner("ü§ñ Creating professional email..."):
                prompt = f"""
                Create a professional {email_type.lower()} email:
                
                Recipient: {recipient_name}
                Company: {company_name}
                Context: {additional_context}
                
                Requirements:
                1. Professional tone
                2. Appropriate subject line
                3. Clear and concise
                4. Action-oriented closing
                5. Under 200 words
                
                Format: Subject line followed by email body
                """
                
                email_content = generate_with_gemini(prompt, max_tokens=800)
                st.markdown(email_content)
                st.download_button(
                    "üì• Download Email",
                    email_content,
                    f"{email_type.lower().replace(' ', '_')}_email.txt",
                    "text/plain"
                )
    
    elif "üéØ Interview Answers" in ai_feature:
        st.subheader("üéØ Interview Answer Generator")
        
        if hasattr(st.session_state, 'resume_text') and hasattr(st.session_state, 'jd_text'):
            question_type = st.selectbox("Question Type:", [
                "Tell me about yourself",
                "Why do you want this job?",
                "What's your greatest strength?",
                "What's your biggest weakness?",
                "Describe a challenge you overcame",
                "Where do you see yourself in 5 years?",
                "Why are you leaving your current job?",
                "Custom Question"
            ])
            
            if question_type == "Custom Question":
                custom_question = st.text_input("Enter your question:", placeholder="e.g., How do you handle conflict?")
                question_to_use = custom_question
            else:
                question_to_use = question_type
            
            if st.button("‚ú® Generate Answer", type="primary"):
                if question_to_use:
                    with st.spinner("ü§ñ Creating personalized answer..."):
                        prompt = f"""
                        Create a personalized interview answer for:
                        
                        Question: {question_to_use}
                        Resume: {st.session_state.resume_text[:1500]}
                        Job Description: {st.session_state.jd_text[:1000]}
                        
                        Provide:
                        1. STAR method structure (if applicable)
                        2. Specific examples from the resume
                        3. Connection to the target role
                        4. Key points to emphasize
                        5. Confident closing statement
                        
                        Keep answer 60-90 seconds when spoken.
                        """
                        
                        answer = generate_with_gemini(prompt, max_tokens=1000)
                        st.markdown(answer)
                        st.download_button(
                            "üì• Download Answer",
                            answer,
                            "interview_answer.txt",
                            "text/plain"
                        )
                else:
                    st.error("Please enter a question")
        else:
            st.error("Please analyze a resume first")
    
    elif "üîÑ Career Transition" in ai_feature:
        st.subheader("üîÑ Career Transition Planner")
        
        if hasattr(st.session_state, 'resume_text'):
            col1, col2 = st.columns(2)
            with col1:
                current_role = st.text_input("Current Role:", placeholder="e.g., Marketing Manager")
                target_role = st.text_input("Target Role:", placeholder="e.g., Product Manager")
            with col2:
                timeline = st.selectbox("Timeline:", ["3 months", "6 months", "1 year", "2+ years"])
                experience_level = st.selectbox("Experience Level:", ["Entry Level", "Mid Level", "Senior Level", "Executive"])
            
            if st.button("‚ú® Create Transition Plan", type="primary"):
                if current_role and target_role:
                    with st.spinner("ü§ñ Creating transition plan..."):
                        prompt = f"""
                        Create a comprehensive career transition plan:
                        
                        Current Role: {current_role}
                        Target Role: {target_role}
                        Timeline: {timeline}
                        Experience Level: {experience_level}
                        Current Resume: {st.session_state.resume_text[:1500]}
                        
                        Provide:
                        1. Skill Gap Analysis (what's missing)
                        2. Learning Path (courses, certifications)
                        3. Experience Building (projects, volunteering)
                        4. Networking Strategy
                        5. Timeline Milestones
                        6. Resume Positioning Tips
                        7. Interview Preparation Focus
                        8. Potential Challenges & Solutions
                        
                        Make it actionable and specific to the {timeline} timeline.
                        """
                        
                        plan = generate_with_gemini(prompt, max_tokens=2000)
                        st.markdown(plan)
                        st.download_button(
                            "üì• Download Plan",
                            plan,
                            "career_transition_plan.txt",
                            "text/plain"
                        )
                else:
                    st.error("Please enter current and target roles")
        else:
            st.error("Please analyze a resume first")
    
    else:
        st.info("üöÄ Select an AI tool above to get started!")
        st.markdown("**Available Tools:**")
        st.write("‚Ä¢ üí∞ Salary Negotiation Guide - Personalized negotiation strategy")
        st.write("‚Ä¢ üè¢ Company Research Report - Comprehensive company analysis")
        st.write("‚Ä¢ üíº LinkedIn Optimization - Profile enhancement tips")
        st.write("‚Ä¢ üìß Professional Email Generator - Professional communication templates")
        st.write("‚Ä¢ üéØ Interview Answer Generator - Personalized STAR method answers")
        st.write("‚Ä¢ üîÑ Career Transition Planner - Strategic career change guidance")

def show_analytics_dashboard():
    st.header("üìà Advanced Analytics Dashboard")
    
    if st.session_state.user_data:
        sessions = get_user_sessions(st.session_state.user_data['id'])
        
        if sessions:
            # Enhanced metrics with cards
            st.subheader("üìà Performance Overview")
            
            total_analyses = len(sessions)
            avg_match = sum(s[4] for s in sessions) / len(sessions)
            avg_ats = sum(s[5] for s in sessions) / len(sessions)
            best_score = max(s[4] for s in sessions)
            
            # Create styled metric cards
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.markdown(f'''
                <div class="metric-card" style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; text-align: center; padding: 1.5rem; border-radius: 10px; margin: 0.5rem 0;">
                    <h3 style="margin: 0; font-size: 2rem;">{total_analyses}</h3>
                    <p style="margin: 0; opacity: 0.9;">üìÜ Total Analyses</p>
                </div>
                ''', unsafe_allow_html=True)
            
            with col2:
                match_color = "#e74c3c" if avg_match < 50 else "#f39c12" if avg_match < 70 else "#27ae60"
                st.markdown(f'''
                <div class="metric-card" style="background: {match_color}; color: white; text-align: center; padding: 1.5rem; border-radius: 10px; margin: 0.5rem 0;">
                    <h3 style="margin: 0; font-size: 2rem;">{avg_match:.1f}%</h3>
                    <p style="margin: 0; opacity: 0.9;">üéØ Avg Match Score</p>
                </div>
                ''', unsafe_allow_html=True)
            
            with col3:
                ats_color = "#e74c3c" if avg_ats < 50 else "#f39c12" if avg_ats < 70 else "#27ae60"
                st.markdown(f'''
                <div class="metric-card" style="background: {ats_color}; color: white; text-align: center; padding: 1.5rem; border-radius: 10px; margin: 0.5rem 0;">
                    <h3 style="margin: 0; font-size: 2rem;">{avg_ats:.1f}%</h3>
                    <p style="margin: 0; opacity: 0.9;">üìà Avg ATS Score</p>
                </div>
                ''', unsafe_allow_html=True)
            
            with col4:
                best_color = "#8e44ad" if best_score >= 80 else "#3498db" if best_score >= 60 else "#95a5a6"
                st.markdown(f'''
                <div class="metric-card" style="background: {best_color}; color: white; text-align: center; padding: 1.5rem; border-radius: 10px; margin: 0.5rem 0;">
                    <h3 style="margin: 0; font-size: 2rem;">{best_score:.1f}%</h3>
                    <p style="margin: 0; opacity: 0.9;">üèÜ Best Score</p>
                </div>
                ''', unsafe_allow_html=True)
            
            # Progress chart
            if len(sessions) > 1:
                st.subheader("üìà Progress Over Time")
                
                # Create progress data
                dates = [datetime.strptime(s[7][:19], '%Y-%m-%d %H:%M:%S') for s in sessions[-10:]]
                match_scores = [s[4] for s in sessions[-10:]]
                ats_scores = [s[5] for s in sessions[-10:]]
                
                # Simple line chart
                chart_data = {
                    'Date': dates,
                    'Match Score': match_scores,
                    'ATS Score': ats_scores
                }
                
                st.line_chart(chart_data, x='Date')
            
            # Enhanced Skill Gap Analysis
            st.subheader("üî• Advanced Skill Gap Analysis")
            st.write("*Comprehensive analysis of 50+ skills across 6 categories*")
            
            if len(sessions) >= 1:
                # Use current session data if available, otherwise use latest from database
                if hasattr(st.session_state, 'resume_text') and hasattr(st.session_state, 'jd_text'):
                    resume_text = st.session_state.resume_text
                    jd_text = st.session_state.jd_text
                else:
                    latest_session = sessions[0]
                    resume_text = latest_session[2]
                    jd_text = latest_session[3]
                
                # Advanced skill detection with 50+ skills across 6 categories
                def analyze_skills_comprehensive(resume_text, jd_text):
                    jd_lower = jd_text.lower()
                    resume_lower = resume_text.lower()
                    
                    # 50+ skills across 6 comprehensive categories
                    skill_categories = {
                        'programming_languages': ['python', 'java', 'javascript', 'typescript', 'react', 'angular', 'vue', 'php', 'c#', 'go', 'rust', 'kotlin', 'swift', 'ruby', 'scala'],
                        'databases_storage': ['sql', 'mysql', 'postgresql', 'mongodb', 'redis', 'elasticsearch', 'cassandra', 'dynamodb', 'oracle', 'sqlite'],
                        'cloud_devops': ['aws', 'azure', 'gcp', 'docker', 'kubernetes', 'terraform', 'jenkins', 'ansible', 'prometheus', 'grafana'],
                        'development_tools': ['git', 'github', 'jira', 'figma', 'postman', 'vscode', 'selenium', 'jest', 'junit', 'cypress'],
                        'frameworks_libraries': ['django', 'flask', 'spring', 'express', 'laravel', 'rails', 'bootstrap', 'tailwind', 'jquery', 'nodejs'],
                        'soft_skills_leadership': ['leadership', 'communication', 'teamwork', 'management', 'planning', 'problem solving', 'analytical', 'project management', 'agile', 'scrum']
                    }
                    
                    # Analyze skills by category
                    analysis_results = {}
                    total_found = 0
                    total_missing = 0
                    
                    for category, skills in skill_categories.items():
                        found_skills = []
                        missing_skills = []
                        
                        for skill in skills:
                            # Enhanced matching with word boundaries
                            import re
                            skill_pattern = rf'\b{re.escape(skill)}\b'
                            
                            jd_has_skill = bool(re.search(skill_pattern, jd_lower, re.IGNORECASE))
                            resume_has_skill = bool(re.search(skill_pattern, resume_lower, re.IGNORECASE))
                            
                            if jd_has_skill:
                                if resume_has_skill:
                                    found_skills.append(skill)
                                    total_found += 1
                                else:
                                    missing_skills.append(skill)
                                    total_missing += 1
                        
                        analysis_results[category] = {
                            'found': found_skills,
                            'missing': missing_skills,
                            'category_name': category.replace('_', ' ').title()
                        }
                    
                    return analysis_results, total_found, total_missing
                
                skill_analysis, total_found, total_missing = analyze_skills_comprehensive(resume_text, jd_text)
                

                
                # Calculate comprehensive metrics
                total_required = total_found + total_missing
                skill_match_pct = (total_found / total_required * 100) if total_required > 0 else 0
                
                # Compact metrics
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.markdown(f'''
                    <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 1.5rem; border-radius: 12px; text-align: center; box-shadow: 0 4px 15px rgba(0,0,0,0.1);">
                        <div style="font-size: 2.5rem; font-weight: bold; margin-bottom: 0.5rem;">{total_found}</div>
                        <div style="font-size: 0.9rem; opacity: 0.9;">‚úÖ Skills Found</div>
                    </div>
                    ''', unsafe_allow_html=True)
                
                with col2:
                    missing_color = "linear-gradient(135deg, #e74c3c 0%, #c0392b 100%)" if total_missing > 5 else "linear-gradient(135deg, #f39c12 0%, #e67e22 100%)" if total_missing > 2 else "linear-gradient(135deg, #27ae60 0%, #229954 100%)"
                    st.markdown(f'''
                    <div style="background: {missing_color}; color: white; padding: 1.5rem; border-radius: 12px; text-align: center; box-shadow: 0 4px 15px rgba(0,0,0,0.1);">
                        <div style="font-size: 2.5rem; font-weight: bold; margin-bottom: 0.5rem;">{total_missing}</div>
                        <div style="font-size: 0.9rem; opacity: 0.9;">‚ö†Ô∏è Skills Missing</div>
                    </div>
                    ''', unsafe_allow_html=True)
                
                with col3:
                    match_color = "linear-gradient(135deg, #27ae60 0%, #229954 100%)" if skill_match_pct >= 80 else "linear-gradient(135deg, #f39c12 0%, #e67e22 100%)" if skill_match_pct >= 60 else "linear-gradient(135deg, #e74c3c 0%, #c0392b 100%)"
                    st.markdown(f'''
                    <div style="background: {match_color}; color: white; padding: 1.5rem; border-radius: 12px; text-align: center; box-shadow: 0 4px 15px rgba(0,0,0,0.1);">
                        <div style="font-size: 2.5rem; font-weight: bold; margin-bottom: 0.5rem;">{skill_match_pct:.0f}%</div>
                        <div style="font-size: 0.9rem; opacity: 0.9;">üìä Match Rate</div>
                    </div>
                    ''', unsafe_allow_html=True)
                

                
                # Compact skills breakdown
                st.markdown("### üéØ Skills by Category")
                
                for category, data in skill_analysis.items():
                    if data['found'] or data['missing']:
                        category_name = data['category_name']
                        found_count = len(data['found'])
                        missing_count = len(data['missing'])
                        total_category = found_count + missing_count
                        category_pct = (found_count / total_category * 100) if total_category > 0 else 0
                        
                        with st.expander(f"{category_name} ({found_count}/{total_category})", expanded=False):
                            col1, col2 = st.columns(2)
                            
                            with col1:
                                if data['found']:
                                    st.write(f"‚úÖ **Found:** {', '.join(data['found'])}")
                            
                            with col2:
                                if data['missing']:
                                    st.write(f"‚ùå **Missing:** {', '.join(data['missing'])}")
                                else:
                                    st.write("‚úÖ **All skills present**")

                
                # Compact recommendations
                if total_missing > 0:
                    st.markdown("### üí° Recommendations")
                    
                    priority_skills = []
                    for category, data in skill_analysis.items():
                        if data['missing']:
                            top_missing = data['missing'][:2]
                            if top_missing:
                                priority_skills.append(f"**{data['category_name']}**: {', '.join(top_missing)}")
                    
                    for skill_rec in priority_skills[:3]:
                        st.write(f"üîπ {skill_rec}")
                    
                    if skill_match_pct >= 80:
                        st.success("üéâ **Excellent match!** Focus on showcasing your expertise.")
                    elif skill_match_pct >= 60:
                        st.warning("üìà **Good foundation** - Address key skill gaps above.")
                    else:
                        st.error("üìâ **Significant gaps** - Consider upskilling or entry-level roles.")
                else:
                    st.success("üéÜ **Perfect alignment!** Focus on demonstrating expertise with examples.")
            else:
                st.info("üìà **Complete a resume analysis first to see detailed skill gap analysis**")

            

            
            # Job matching simulation
            st.markdown("---")
            st.subheader("üîç Smart Job Matching")
            
            job_search = st.text_input("üîç Search job titles or companies:", placeholder="e.g., Software Engineer, Google")
            
            if job_search:
                # Simulate job matches
                sample_jobs = [
                    {"title": "Senior Software Engineer", "company": "TechCorp", "match": 85, "salary": "$120k-150k"},
                    {"title": "Full Stack Developer", "company": "StartupXYZ", "match": 78, "salary": "$90k-120k"},
                    {"title": "Software Engineer II", "company": "BigTech", "match": 72, "salary": "$110k-140k"},
                    {"title": "Frontend Developer", "company": "WebCorp", "match": 68, "salary": "$80k-110k"}
                ]
                
                st.write(f"üìà **Found {len(sample_jobs)} matching jobs:**")
                
                for i, job in enumerate(sample_jobs):
                    with st.expander(f"{job['title']} at {job['company']} - {job['match']}% match"):
                        col1, col2, col3 = st.columns(3)
                        
                        with col1:
                            st.metric("Match Score", f"{job['match']}%")
                        with col2:
                            st.metric("Salary Range", job['salary'])
                        with col3:
                            if st.button(f"Apply", key=f"apply_{i}"):
                                st.success(f"‚úÖ Application tracked!")
        else:
            st.info("üìà Complete your first analysis to see analytics!")
    else:
        st.error("Please log in to view analytics")

def show_job_matching():
    """Enhanced job matching with compatibility scoring"""
    st.subheader("üéØ Job Compatibility Analysis")
    
    if hasattr(st.session_state, 'resume_text'):
        # Job input
        job_url = st.text_input("üîó Job URL or paste job description:", placeholder="Paste job posting here...")
        
        if job_url:
            # Simulate compatibility analysis
            compatibility_score = 75  # Would be calculated based on resume vs job
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("üéØ Compatibility", f"{compatibility_score}%")
            with col2:
                st.metric("üìà Success Rate", "68%")
            with col3:
                st.metric("üí∞ Salary Match", "$95k-125k")
            
            # Improvement suggestions
            st.write("üí° **To improve compatibility:**")
            st.write("‚Ä¢ Add 'Python' and 'AWS' to skills section")
            st.write("‚Ä¢ Quantify your project management experience")
            st.write("‚Ä¢ Include 'Agile' methodology experience")
    else:
        st.info("üìÑ Upload a resume first to analyze job compatibility")

if __name__ == "__main__":
    main()
